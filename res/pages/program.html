<div class='top100'></div>
<h1 class='pageTitle'> Program </h1>

<div class='content'>
  
  <button onclick='dayClicked(0)' class='card'>
    <h2>Day 1</h2>
    <h3>Thu, October 10th</h3>
  </button>
  <button onclick='dayClicked(1)' class='card'>
    <h2>Day 2</h2>
    <h3>Fri, October 11th</h3>
  </button>
  <button onclick='dayClicked(2)' class='card'>
    <h2>Day 3</h2>
    <h3>Fri, October 12th</h3>
  </button>
  
  <div id="accordion" class="">
    <h2 class='tcenter' id='d1wp'>Day 1</h2>
    <h3 class='tcenter'>Thu, October 10th</h3>
    <h4 class='tcenter'>
      <span class='greenDot'></span> Performance
      <span class='yellowDot'></span> Breaks
      <span class='blueDot'></span> Presentaion
    </h4>
			<div class='pcard'>
        <label><span class='blueDot'></span><span class='clock'></span>12:00-16:30</label>
				<div class='article'>
            REGISTRATION OPEN
				</div>
			</div>

      <div class='hr'></div>

			<div class='pcard'>
				<input type="checkbox" id="check-1" />
				<label for="check-1"><span class='blueDot'></span><span class='clock'></span>12:00-12:30</label>
          <h3> Retrieving Human Traits From Gesture In Sign Language : The Example Of Gestural Identity </h3>
          <h4>FÃ©lix Bigand, Elise Prigent and Annelies Braffort </h4>
          <h4><a href='javascript:goto("saffb")'><span class='pin'></span> Stauffer B </a></h4>
				<article>
  ABSTRACT. Virtual signers (or signing avatars) play an important role in the accesibility of information in sign languages. They have been developed notably for their capability to anonymize the signer's appearance and to enable dynamic or interactive scenarios. Recording real movements thanks to motion capture provides human-like, realistic and comprehensible signing animations. However, such accurate systems may also convey extralinguistic information such as identity, gender or emotional state. In the present work, we want to address the problem of gestural identity in the context of animated agents in French Sign Language (LSF). On the one hand, person identification from signing motion is assessed through psychophysical experiments, using point-light displays. On the other hand, a computational framework is developed for the analysis of LSF motion in order to investigate which features are critical for identification. For some applications, determining these movement parameters will enable controlling the gestural human traits of virtual signers.
				</article>
			</div>

      <div class='hr'></div>

			<div class='pcard'>
				<input type="checkbox" id="check-3" />
				<label for="check-3"><span class='blueDot'></span><span class='clock'></span>12:30-13:00</label>
        <h3>Tracing from Sound to Movement with Mixture Density Recurrent Neural Networks </h3>
        <h4>	Benedikte Wallace, Charles P. Martin and Kristan Nymoen</h4>
        <h4><a href='javascript:goto("saffb")'><span class='pin'></span> Stauffer B </a></h4>
				<article>
ABSTRACT. In this work, we present a method for generating 3D tracings of perceived sound features, sound-tracings, using a Mixture-Density Recurrent Neural Net (MDRNN). By training the model on a data set of single point sound-tracings and the sound features extracted from short sounds (2 to 4 seconds) the model learns to generate novel tracings using multi-modal input. This is part of an ongoing research effort to examine the complex correlations between sound and movement and the possibility of modelling these relationships using deep learning techniques.
				</article>
			</div>

      <div class='hr'></div>

			<div class='pcard'>
				<input type="checkbox" id="check-4" />
				<label for="check-4"><span class='blueDot'></span><span class='clock'></span>13:00-13:30</label>
        <h3>Towards AI-Enhanced Ballet Learning</h3>
        <h4>	Milka Trajkova </h4>
				<article>
          ABSTRACT. Since its codified genesis in the 18th century, ballet training has largely been unchanged: it relies on the word of mouth expertise passed down generation to generation and in tools that do not adequately support both dancers and teachers. Moreover, top-tier training is only found in a few locations around the world and comes at an exceptional price. In this context, artificial intelligence (AI)-based video tools might represent an affordable and non-invasive alternative: it would allow dancers and teachers to self-assess as well as enable skilled dance teachers to connect with a wider audience. In my research, I study how to design and evaluate AI-based tools to improve ballet performance for dancers and teachers.
				</article>
			</div>


      <div class='hr'></div>

			<div class='pcard'>
				<input type="checkbox" id="check-" />
				<label for="check-">Option 1</label>
				<article>
				</article>
			</div>

    <h2 class='tcenter' id='d2wp'>Day 2</h2>
    <h3 class='tcenter'>Fri, October 11th</h3>
    <h4 class='tcenter'>
      <span class='greenDot'></span> Performance
      <span class='yellowDot'></span> Breaks
      <span class='blueDot'></span> Presentaion
    </h4>

    <h2 class='tcenter' id='d3wp'>Day 3</h2>
    <h3 class='tcenter'>Sat, October 12th</h3>
    <h4 class='tcenter'>
      <span class='greenDot'></span> Performance
      <span class='yellowDot'></span> Breaks
      <span class='blueDot'></span> Presentaion
    </h4>

  </div>
</div>

